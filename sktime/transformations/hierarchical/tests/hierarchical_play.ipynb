{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sktime.datatypes import get_examples\n",
    "from sktime.transformations.hierarchical.aggregate import aggregator\n",
    "from sktime.transformations.hierarchical.reconcile import reconciler\n",
    "\n",
    "# https://otexts.com/fpp3/hierarchical.html\n",
    "# https://github.com/robjhyndman/reconciliation_review_talk/blob/main/10years_reconciliation.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_examples(mtype=\"pd_multiindex_hier\", as_scitype=\"Hierarchical\")\n",
    "df = df[0]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the full forecasting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = aggregator(flatten_single_levels=True)\n",
    "\n",
    "agg_df.fit_transform(X=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test with bottom levels that span two nodes\n",
    "\n",
    "- i.e. mid levels that are only present at a subset of bottom nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"foo\", \"foo2\", \"bar\", \"timepoints\"] + [f\"var_{i}\" for i in range(2)]\n",
    "\n",
    "Xlist = [\n",
    "    pd.DataFrame(\n",
    "        [[\"a\", \"a1\", 0, 0, 1, 4], [\"a\", \"a1\", 0, 1, 2, 5], [\"a\", \"a1\", 0, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"a\", \"a1\", 1, 0, 1, 4], [\"a\", \"a1\", 1, 1, 2, 55], [\"a\", \"a1\", 1, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"a\", \"a2\", 2, 0, 1, 42], [\"a\", \"a2\", 2, 1, 2, 5], [\"a\", \"a2\", 2, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"b\", \"b1\", 0, 0, 1, 4], [\"b\", \"b1\", 0, 1, 2, 5], [\"b\", \"b1\", 0, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"b\", \"b2\", 1, 0, 1, 4], [\"b\", \"b2\", 1, 1, 2, 55], [\"b\", \"b2\", 1, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"b\", \"b2\", 2, 0, 1, 42], [\"b\", \"b2\", 2, 1, 2, 5], [\"b\", \"b2\", 2, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "]\n",
    "X = pd.concat(Xlist)\n",
    "X = X.set_index([\"foo\", \"foo2\", \"bar\", \"timepoints\"])\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note flatten single levels is the default option\n",
    "\n",
    "- see that `(a, a2, 2, *)` and `(b, b1, 0, *)` don't contain `__total`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = aggregator(flatten_single_levels=True)\n",
    "agg_df.fit_transform(X=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = aggregator(flatten_single_levels=False)\n",
    "agg_df.fit_transform(X=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Example\n",
    "\n",
    "Let's generate a hierarchical dataset similar to the last example from the flights dataset\n",
    "\n",
    "- Generate dataset\n",
    "- Generate full hierarchy\n",
    "- Forecast each level\n",
    "- Reconcile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.utils.plotting import plot_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone1 = load_airline()\n",
    "\n",
    "zone1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting for visualization\n",
    "plot_series(\n",
    "    zone1,\n",
    "    10 + zone1 * 5,\n",
    "    -50 + zone1 * 0.9,\n",
    "    zone1 ** 1.5,\n",
    "    -20 + 10 * zone1,\n",
    "    10 + (10 * zone1) + (0.05 * (zone1 ** 2)),\n",
    "    labels=[\"zone1\", \"zone2\", \"zone3\", \"zone4\", \"zone5\", \"zone6\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zone1, index=zone1.index).rename(\n",
    "    columns={\"Number of airline passengers\": \"zone1\"}\n",
    ")\n",
    "\n",
    "df[\"zone2\"] = 10 + zone1 * 5\n",
    "df[\"zone3\"] = zone1 * 0.9 - 50\n",
    "df[\"zone4\"] = zone1 ** 1.5\n",
    "df[\"zone5\"] = zone1 * 10 - 500\n",
    "df[\"zone6\"] = 10 + (10 * zone1) + (0.05 * (zone1 ** 2))\n",
    "\n",
    "df = (\n",
    "    df.melt(ignore_index=False)\n",
    "    .set_index([\"variable\", df.melt(ignore_index=False).index])\n",
    "    .rename_axis([\"airport\", \"timepoints\"], axis=0)\n",
    "    .rename(columns={\"value\": \"passengers\"})\n",
    ")\n",
    "\n",
    "# df['country'] = \"USA\"\n",
    "df.loc[\n",
    "    df.index.get_level_values(level=\"airport\").isin([\"zone1\", \"zone2\", \"zone3\"]),\n",
    "    \"state\",\n",
    "] = \"CA\"\n",
    "df.loc[\n",
    "    df.index.get_level_values(level=\"airport\").isin([\"zone1\", \"zone2\"]), \"city\"\n",
    "] = \"LA\"\n",
    "df.loc[df.index.get_level_values(level=\"airport\").isin([\"zone3\"]), \"city\"] = \"SF\"\n",
    "\n",
    "\n",
    "df.loc[\n",
    "    df.index.get_level_values(level=\"airport\").isin([\"zone4\", \"zone5\", \"zone6\"]),\n",
    "    \"state\",\n",
    "] = \"NY\"\n",
    "df.loc[\n",
    "    df.index.get_level_values(level=\"airport\").isin([\"zone4\", \"zone5\"]), \"city\"\n",
    "] = \"NYC\"\n",
    "df.loc[df.index.get_level_values(level=\"airport\").isin([\"zone6\"]), \"city\"] = \"BF\"\n",
    "\n",
    "df = df.set_index([\"state\", \"city\", df.index])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate full hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = aggregator(flatten_single_levels=True)\n",
    "df_fh = agg_df.fit_transform(X=df)\n",
    "\n",
    "df_fh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast each level\n",
    "\n",
    "here we will forecast each unique level outside `timepoints`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
    "\n",
    "# from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "# from sktime.performance_metrics.forecasting import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids = df_fh.droplevel(level=\"timepoints\").index.unique()\n",
    "\n",
    "model_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will automatically to a panel type forecaster!\n",
    "fh = ForecastingHorizon([*range(1, 12)], is_relative=True)\n",
    "forecaster = ExponentialSmoothing(trend=\"add\", seasonal=\"additive\", sp=12)\n",
    "mods = forecaster.fit(df_fh)\n",
    "prds = forecaster.predict(fh)\n",
    "prds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconcile - Bottom Up\n",
    "\n",
    "Bottom up is easy we just sum the bottome levels much like aggregate function.\n",
    "\n",
    "But we want it to be compatible with other methods which go like\n",
    "    \n",
    "    - get y 'base' forecasts for all series (previous section)\n",
    "    - get S matrix from df index (defined by hierarchy structure)\n",
    "    - get G matrix for recon (defined by recon method)\n",
    "    - reconcile forecasts - SGy (all methods)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = reconciler(method=\"bu\")\n",
    "\n",
    "fitted_transfrom = transformer.fit(X=prds[[\"passengers\"]])\n",
    "\n",
    "fitted_transfrom.s_matrix\n",
    "\n",
    "# https://stackoverflow.com/questions/54307300/what-causes-indexing-past-lexsort-depth-warning-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_transfrom.g_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prds[\"y_recon_bu\"] = fitted_transfrom.transform(X=prds[[\"passengers\"]])\n",
    "\n",
    "prds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prds.loc[prds.index.get_level_values(level=-1) == \"1961-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS reconciliation\n",
    "\n",
    "    - Now all we need is the new g_matrix method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_ols = reconciler(method=\"ols\")\n",
    "\n",
    "fitted_transfrom_ols = transformer_ols.fit(X=prds[[\"passengers\"]])\n",
    "\n",
    "fitted_transfrom_ols.g_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prds[\"y_recon_ols\"] = fitted_transfrom_ols.transform(X=prds[[\"passengers\"]])\n",
    "\n",
    "prds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work fine as well\n",
    "\n",
    "    - note the bottom level forecasts have now changed as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prds.loc[prds.index.get_level_values(level=-1) == \"1961-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WLS structural reconciliation\n",
    "\n",
    "    - Now all we need is the new g_matrix method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_wls = reconciler(method=\"wls_str\")\n",
    "\n",
    "fitted_transfrom_wls = transformer_wls.fit(X=prds[[\"passengers\"]])\n",
    "\n",
    "fitted_transfrom_wls.g_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prds[\"y_recon_wls\"] = fitted_transfrom_wls.transform(X=prds[[\"passengers\"]])\n",
    "\n",
    "prds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prds.loc[prds.index.get_level_values(level=-1) == \"1961-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "here is the aggregator/forecaster/reconciler in a pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sktime.forecasting.compose import TransformedTargetForecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecaster = TransformedTargetForecaster(\n",
    "#     [\n",
    "#         (\"aggregate\", aggregator(flatten_single_levels=True)),\n",
    "#         (\"forecast\", ExponentialSmoothing(trend=\"add\", seasonal=\"additive\", sp=12))\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# forecaster.fit(df_fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fh = ForecastingHorizon([*range(1, 12)], is_relative=True)\n",
    "# prds = forecaster.predict(fh)\n",
    "# prds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduce tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok for aggregator check that\n",
    "\n",
    "    -    test that \"__total\" is not named in index\n",
    "    -    test that the final index is timestamp type - this is done in the package elsewhere (:)\n",
    "    -    test that the index is actually named\n",
    "    -    that we actually have two indexes - why is this not working from rest of package?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone1.index.name = \"time\"\n",
    "zone1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this shouldn't work - BUT DOES?!\n",
    "agg_df = aggregator(flatten_single_levels=True)\n",
    "agg_df.fit_transform(X=zone1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this shouldn't work\n",
    "agg_df = aggregator(flatten_single_levels=True)\n",
    "agg_df.fit_transform(X=prds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this shouldn't work\n",
    "agg_df = aggregator(flatten_single_levels=True)\n",
    "agg_df.fit_transform(X=df_fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test reconciliation works\n",
    "test_df = prds.loc[\n",
    "    prds.index.get_level_values(level=-2) != \"__total\", prds.columns[1:4]\n",
    "].copy()\n",
    "test_df.index.names = [\"state\", \"city\", \"airport\", \"timepoints\"]\n",
    "\n",
    "agg_df = aggregator(flatten_single_levels=True)\n",
    "test_df = agg_df.fit_transform(X=test_df)\n",
    "test_df.index.names = [\"state\", \"city\", \"airport\", None]\n",
    "# test_df.equals(prds[prds.columns[1:4]])\n",
    "(test_df - prds[prds.columns[1:4]]).apply(lambda x: x.round(6).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1eb1c2818a749c31c67be5c4cb66d4609f775387358a3054790d55ee191d060"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('sktime-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
