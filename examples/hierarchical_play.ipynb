{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sktime.datatypes import get_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_examples(mtype=\"pd_multiindex_hier\", as_scitype=\"Hierarchical\")\n",
    "df = df[0]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_hierarchy(df_hier, flatten_single_levels=True):\n",
    "    \"\"\"From hierarchical mtype get the full aggregate hierarchy before forecasting\"\"\"\n",
    "\n",
    "    hier_names = list(df_hier.index.names)\n",
    "\n",
    "    # top level\n",
    "    # remove aggregations that only have one level from below\n",
    "    if flatten_single_levels:\n",
    "        single_df = df_hier.groupby([\"timepoints\"]).count()\n",
    "        mask1 = (\n",
    "            single_df[(single_df > 1).all(1)]\n",
    "            .index.get_level_values(\"timepoints\")\n",
    "            .unique()\n",
    "        )\n",
    "        mask1 = df_hier.index.get_level_values(\"timepoints\").isin(mask1)\n",
    "        top = df_hier.loc[mask1].groupby(level=[\"timepoints\"]).sum()\n",
    "    else:\n",
    "        top = df_hier.loc[mask1].groupby(level=[\"timepoints\"]).sum()\n",
    "\n",
    "    ind_names = list(set(hier_names).difference([\"timepoints\"]))\n",
    "    for i in ind_names:\n",
    "        top[i] = \"__total\"\n",
    "\n",
    "    top = top.set_index(ind_names, append=True).reorder_levels(hier_names)\n",
    "\n",
    "    df_out = pd.concat([top, df_hier])\n",
    "\n",
    "    # if we have a hierarchy with mid levels\n",
    "    if len(hier_names) > 2:\n",
    "        for i in range(len(hier_names) - 2):\n",
    "            # list of levels to aggregate\n",
    "            agg_levels = hier_names[0 : (i + 1)]\n",
    "            agg_levels.append(\"timepoints\")\n",
    "\n",
    "            # remove aggregations that only have one level from below\n",
    "            if flatten_single_levels:\n",
    "                single_df = df_hier.groupby(level=agg_levels).count()\n",
    "                # get index masks\n",
    "                masks = []\n",
    "                for i in agg_levels:\n",
    "                    m1 = (\n",
    "                        single_df[(single_df > 1).all(1)]\n",
    "                        .index.get_level_values(i)\n",
    "                        .unique()\n",
    "                    )\n",
    "                    m1 = df_hier.index.get_level_values(i).isin(m1)\n",
    "                    masks.append(m1)\n",
    "                mid = (\n",
    "                    df_hier.loc[np.logical_and.reduce(masks)]\n",
    "                    .groupby(level=agg_levels)\n",
    "                    .sum()\n",
    "                )\n",
    "            else:\n",
    "                mid = df_hier.groupby(level=agg_levels).sum()\n",
    "\n",
    "            # now fill in index\n",
    "            ind_names = list(set(hier_names).difference(agg_levels))\n",
    "            for j in ind_names:\n",
    "                mid[j] = \"__total\"\n",
    "            # set back in index\n",
    "            mid = mid.set_index(ind_names, append=True).reorder_levels(hier_names)\n",
    "            df_out = pd.concat([df_out, mid])\n",
    "\n",
    "    df_out.sort_index(inplace=True)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the full forecasting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_hierarchy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test with bottom levels that span two nodes\n",
    "\n",
    "- i.e. mid levels that are only present at a subset of bottom nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"foo\", \"foo2\", \"bar\", \"timepoints\"] + [f\"var_{i}\" for i in range(2)]\n",
    "\n",
    "Xlist = [\n",
    "    pd.DataFrame(\n",
    "        [[\"a\", \"a1\", 0, 0, 1, 4], [\"a\", \"a1\", 0, 1, 2, 5], [\"a\", \"a1\", 0, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"a\", \"a1\", 1, 0, 1, 4], [\"a\", \"a1\", 1, 1, 2, 55], [\"a\", \"a1\", 1, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"a\", \"a2\", 2, 0, 1, 42], [\"a\", \"a2\", 2, 1, 2, 5], [\"a\", \"a2\", 2, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"b\", \"b1\", 0, 0, 1, 4], [\"b\", \"b1\", 0, 1, 2, 5], [\"b\", \"b1\", 0, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"b\", \"b2\", 1, 0, 1, 4], [\"b\", \"b2\", 1, 1, 2, 55], [\"b\", \"b2\", 1, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"b\", \"b2\", 2, 0, 1, 42], [\"b\", \"b2\", 2, 1, 2, 5], [\"b\", \"b2\", 2, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "]\n",
    "X = pd.concat(Xlist)\n",
    "X = X.set_index([\"foo\", \"foo2\", \"bar\", \"timepoints\"])\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note flatten single levels is the default option\n",
    "\n",
    "- see that `(a, a2, 2, *)` and `(b, b1, 0, *)` don't contain `__total`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_hierarchy(X, flatten_single_levels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Example\n",
    "\n",
    "Let's generate a hierarchical dataset similar to the last example from the flights dataset\n",
    "\n",
    "- Generate dataset\n",
    "- Generate full hierarchy\n",
    "- Forecast each level\n",
    "- Reconcile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.utils.plotting import plot_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone1 = load_airline()\n",
    "\n",
    "zone1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting for visualization\n",
    "plot_series(\n",
    "    zone1,\n",
    "    10 + zone1 * 5,\n",
    "    -50 + zone1 * 0.9,\n",
    "    zone1 ** 1.5,\n",
    "    -20 + 10 * zone1,\n",
    "    10 + (10 * zone1) + (0.05 * (zone1 ** 2)),\n",
    "    labels=[\"zone1\", \"zone2\", \"zone3\", \"zone4\", \"zone5\", \"zone6\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zone1, index=zone1.index).rename(\n",
    "    columns={\"Number of airline passengers\": \"zone1\"}\n",
    ")\n",
    "\n",
    "df[\"zone2\"] = 10 + zone1 * 5\n",
    "df[\"zone3\"] = zone1 * 0.9 - 50\n",
    "df[\"zone4\"] = zone1 ** 1.5\n",
    "df[\"zone5\"] = zone1 * 10 - 500\n",
    "df[\"zone6\"] = 10 + (10 * zone1) + (0.05 * (zone1 ** 2))\n",
    "\n",
    "df = (\n",
    "    df.melt(ignore_index=False)\n",
    "    .set_index([\"variable\", df.melt(ignore_index=False).index])\n",
    "    .rename_axis([\"airport\", \"timepoints\"], axis=0)\n",
    "    .rename(columns={\"value\": \"passengers\"})\n",
    ")\n",
    "\n",
    "# df['country'] = \"USA\"\n",
    "df.loc[\n",
    "    df.index.get_level_values(level=\"airport\").isin([\"zone1\", \"zone2\", \"zone3\"]),\n",
    "    \"state\",\n",
    "] = \"CA\"\n",
    "df.loc[\n",
    "    df.index.get_level_values(level=\"airport\").isin([\"zone1\", \"zone2\"]), \"city\"\n",
    "] = \"LA\"\n",
    "df.loc[df.index.get_level_values(level=\"airport\").isin([\"zone3\"]), \"city\"] = \"SF\"\n",
    "\n",
    "\n",
    "df.loc[\n",
    "    df.index.get_level_values(level=\"airport\").isin([\"zone4\", \"zone5\", \"zone6\"]),\n",
    "    \"state\",\n",
    "] = \"NY\"\n",
    "df.loc[\n",
    "    df.index.get_level_values(level=\"airport\").isin([\"zone4\", \"zone5\"]), \"city\"\n",
    "] = \"NYC\"\n",
    "df.loc[df.index.get_level_values(level=\"airport\").isin([\"zone6\"]), \"city\"] = \"BF\"\n",
    "\n",
    "df = df.set_index([\"state\", \"city\", df.index])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate full hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fh = aggregate_hierarchy(df, flatten_single_levels=True)\n",
    "\n",
    "df_fh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast each level\n",
    "\n",
    "here we will forecast each unique level outside `timepoints`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids = df_fh.droplevel(level=\"timepoints\").index.unique()\n",
    "\n",
    "model_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set up loop for forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in model_ids:\n",
    "mods = {}\n",
    "prds = {}\n",
    "\n",
    "for i in model_ids:\n",
    "    # i = model_ids[0]\n",
    "    y_train, y_test = temporal_train_test_split(df_fh.loc[i], test_size=36)\n",
    "    fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
    "    forecaster = ExponentialSmoothing(trend=\"add\", seasonal=\"additive\", sp=12)\n",
    "    mods[i] = forecaster.fit(y_train)\n",
    "    prds[i] = forecaster.predict(fh)\n",
    "    # plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "    print(i)\n",
    "    print(mean_absolute_percentage_error(y_test, prds[i], symmetric=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prds = (\n",
    "    pd.concat(prds)\n",
    "    .rename_axis(df_fh.index.names, axis=0)\n",
    "    .rename(columns={\"passengers\": \"y_pred\"})\n",
    ")\n",
    "\n",
    "# join with meas\n",
    "prds = pd.concat([prds, df_fh], axis=1, join=\"inner\").rename(\n",
    "    columns={\"passengers\": \"y_true\"}\n",
    ")\n",
    "\n",
    "prds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconcile - Bottom Up\n",
    "\n",
    "Bottom up is easy we just sum the bottome levels much like aggregate function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bu = prds.loc[~(prds.index.get_level_values(level=\"airport\").isin([\"__total\"]))]\n",
    "\n",
    "df_bu = aggregate_hierarchy(\n",
    "    df_bu.loc[:, [\"y_pred\"]], flatten_single_levels=True\n",
    ").rename(columns={\"y_pred\": \"y_reco\"})\n",
    "\n",
    "prds = pd.concat([prds, df_bu], axis=1)\n",
    "\n",
    "prds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe need some significance testing here :p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in model_ids:\n",
    "    print(i)\n",
    "    print(\n",
    "        mean_absolute_percentage_error(\n",
    "            prds.loc[i, \"y_true\"], prds.loc[i, \"y_pred\"], symmetric=True\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        mean_absolute_percentage_error(\n",
    "            prds.loc[i, \"y_true\"], prds.loc[i, \"y_reco\"], symmetric=True\n",
    "        )\n",
    "    )\n",
    "    # plot_series(\n",
    "    #     prds.loc[i, 'y_true'],\n",
    "    #     prds.loc[i, 'y_pred'],\n",
    "    #     prds.loc[i, 'y_reco'],\n",
    "    # labels=[\"y_test\", \"y_pred\", \"y_reco\"],\n",
    "    # )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want it to be compatible with other methods which go like\n",
    "    \n",
    "    - get S matrix from index\n",
    "    - reconcile forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s_matrix(df):\n",
    "\n",
    "    # get bottom level indexes\n",
    "    bl_inds = (\n",
    "        df.loc[~(df.index.get_level_values(level=-2).isin([\"__total\"]))]\n",
    "        .index.droplevel(\"timepoints\")\n",
    "        .unique()\n",
    "    )\n",
    "\n",
    "    # get all level indexes\n",
    "    al_inds = df.droplevel(level=\"timepoints\").index.unique()\n",
    "\n",
    "    s_matrix = pd.DataFrame(\n",
    "        [[0.0 for i in range(len(bl_inds))] for i in range(len(al_inds))], index=al_inds\n",
    "    )\n",
    "\n",
    "    #\n",
    "    s_matrix.columns = list(bl_inds.get_level_values(level=-1))\n",
    "\n",
    "    # now insert indicator for bottom level\n",
    "    for i in s_matrix.columns:\n",
    "        s_matrix.loc[s_matrix.index.get_level_values(-1) == i, i] = 1.0\n",
    "\n",
    "    # now for each unique column\n",
    "    for j in s_matrix.columns:\n",
    "\n",
    "        # find bottom index id\n",
    "        inds = list(s_matrix.index[s_matrix.index.get_level_values(level=-1).isin([j])])\n",
    "\n",
    "        # generate new tuples for the aggregate levels\n",
    "        for i in range(len(inds[0])):\n",
    "            tmp = list(inds[i])\n",
    "            tmp[-(i + 1)] = \"__total\"\n",
    "            inds.append(tuple(tmp))\n",
    "\n",
    "        # insrt indicator for aggregates\n",
    "        for i in inds:\n",
    "            s_matrix.loc[i, j] = 1.0\n",
    "\n",
    "    # drop new levels not present in orginal matrix\n",
    "    s_matrix.dropna(inplace=True)\n",
    "\n",
    "    return s_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seems to work lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_test = get_s_matrix(prds)\n",
    "\n",
    "s_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prds_bm = prds.loc[~(prds.index.get_level_values(level=-2).isin([\"__total\"]))]\n",
    "\n",
    "tst = prds_bm[prds_bm.index.get_level_values(level=-1) == \"1958-01\"]\n",
    "\n",
    "tst = tst.droplevel([0, 1, 3])\n",
    "\n",
    "# tst\n",
    "np.dot(s_test, tst[\"y_pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prds[prds.index.get_level_values(level=-1) == \"1958-01\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ols = pd.DataFrame(\n",
    "    np.dot(inv(np.dot(np.transpose(s_test), s_test)), np.transpose(s_test))\n",
    ")\n",
    "\n",
    "g_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = prds[prds.index.get_level_values(level=-1) == \"1958-01\"]\n",
    "\n",
    "tst[\"y_ols\"] = np.dot(s_test, np.dot(g_ols, tst[\"y_pred\"]))\n",
    "\n",
    "tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fh.loc[model_ids[-1]]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1eb1c2818a749c31c67be5c4cb66d4609f775387358a3054790d55ee191d060"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('sktime-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
