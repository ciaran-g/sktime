{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import inv\n",
    "\n",
    "from sktime.datatypes import get_examples\n",
    "\n",
    "# https://otexts.com/fpp3/hierarchical.html\n",
    "# https://github.com/robjhyndman/reconciliation_review_talk/blob/main/10years_reconciliation.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_examples(mtype=\"pd_multiindex_hier\", as_scitype=\"Hierarchical\")\n",
    "df = df[0]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_hierarchy(df_hier, flatten_single_levels=True):\n",
    "    \"\"\"From hierarchical mtype get the full aggregate hierarchy before forecasting\"\"\"\n",
    "\n",
    "    hier_names = list(df_hier.index.names)\n",
    "\n",
    "    # top level\n",
    "    # remove aggregations that only have one level from below\n",
    "    if flatten_single_levels:\n",
    "        single_df = df_hier.groupby([\"timepoints\"]).count()\n",
    "        mask1 = (\n",
    "            single_df[(single_df > 1).all(1)]\n",
    "            .index.get_level_values(\"timepoints\")\n",
    "            .unique()\n",
    "        )\n",
    "        mask1 = df_hier.index.get_level_values(\"timepoints\").isin(mask1)\n",
    "        top = df_hier.loc[mask1].groupby(level=[\"timepoints\"]).sum()\n",
    "    else:\n",
    "        top = df_hier.loc[mask1].groupby(level=[\"timepoints\"]).sum()\n",
    "\n",
    "    ind_names = list(set(hier_names).difference([\"timepoints\"]))\n",
    "    for i in ind_names:\n",
    "        top[i] = \"__total\"\n",
    "\n",
    "    top = top.set_index(ind_names, append=True).reorder_levels(hier_names)\n",
    "\n",
    "    df_out = pd.concat([top, df_hier])\n",
    "\n",
    "    # if we have a hierarchy with mid levels\n",
    "    if len(hier_names) > 2:\n",
    "        for i in range(len(hier_names) - 2):\n",
    "            # list of levels to aggregate\n",
    "            agg_levels = hier_names[0 : (i + 1)]\n",
    "            agg_levels.append(\"timepoints\")\n",
    "\n",
    "            # remove aggregations that only have one level from below\n",
    "            if flatten_single_levels:\n",
    "                single_df = df_hier.groupby(level=agg_levels).count()\n",
    "                # get index masks\n",
    "                masks = []\n",
    "                for i in agg_levels:\n",
    "                    m1 = (\n",
    "                        single_df[(single_df > 1).all(1)]\n",
    "                        .index.get_level_values(i)\n",
    "                        .unique()\n",
    "                    )\n",
    "                    m1 = df_hier.index.get_level_values(i).isin(m1)\n",
    "                    masks.append(m1)\n",
    "                mid = (\n",
    "                    df_hier.loc[np.logical_and.reduce(masks)]\n",
    "                    .groupby(level=agg_levels)\n",
    "                    .sum()\n",
    "                )\n",
    "            else:\n",
    "                mid = df_hier.groupby(level=agg_levels).sum()\n",
    "\n",
    "            # now fill in index\n",
    "            ind_names = list(set(hier_names).difference(agg_levels))\n",
    "            for j in ind_names:\n",
    "                mid[j] = \"__total\"\n",
    "            # set back in index\n",
    "            mid = mid.set_index(ind_names, append=True).reorder_levels(hier_names)\n",
    "            df_out = pd.concat([df_out, mid])\n",
    "\n",
    "    df_out.sort_index(inplace=True)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the full forecasting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_hierarchy(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test with bottom levels that span two nodes\n",
    "\n",
    "- i.e. mid levels that are only present at a subset of bottom nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"foo\", \"foo2\", \"bar\", \"timepoints\"] + [f\"var_{i}\" for i in range(2)]\n",
    "\n",
    "Xlist = [\n",
    "    pd.DataFrame(\n",
    "        [[\"a\", \"a1\", 0, 0, 1, 4], [\"a\", \"a1\", 0, 1, 2, 5], [\"a\", \"a1\", 0, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"a\", \"a1\", 1, 0, 1, 4], [\"a\", \"a1\", 1, 1, 2, 55], [\"a\", \"a1\", 1, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"a\", \"a2\", 2, 0, 1, 42], [\"a\", \"a2\", 2, 1, 2, 5], [\"a\", \"a2\", 2, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"b\", \"b1\", 0, 0, 1, 4], [\"b\", \"b1\", 0, 1, 2, 5], [\"b\", \"b1\", 0, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"b\", \"b2\", 1, 0, 1, 4], [\"b\", \"b2\", 1, 1, 2, 55], [\"b\", \"b2\", 1, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "    pd.DataFrame(\n",
    "        [[\"b\", \"b2\", 2, 0, 1, 42], [\"b\", \"b2\", 2, 1, 2, 5], [\"b\", \"b2\", 2, 2, 3, 6]],\n",
    "        columns=cols,\n",
    "    ),\n",
    "]\n",
    "X = pd.concat(Xlist)\n",
    "X = X.set_index([\"foo\", \"foo2\", \"bar\", \"timepoints\"])\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note flatten single levels is the default option\n",
    "\n",
    "- see that `(a, a2, 2, *)` and `(b, b1, 0, *)` don't contain `__total`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_hierarchy(X, flatten_single_levels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting Example\n",
    "\n",
    "Let's generate a hierarchical dataset similar to the last example from the flights dataset\n",
    "\n",
    "- Generate dataset\n",
    "- Generate full hierarchy\n",
    "- Forecast each level\n",
    "- Reconcile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.utils.plotting import plot_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone1 = load_airline()\n",
    "\n",
    "zone1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting for visualization\n",
    "plot_series(\n",
    "    zone1,\n",
    "    10 + zone1 * 5,\n",
    "    -50 + zone1 * 0.9,\n",
    "    zone1 ** 1.5,\n",
    "    -20 + 10 * zone1,\n",
    "    10 + (10 * zone1) + (0.05 * (zone1 ** 2)),\n",
    "    labels=[\"zone1\", \"zone2\", \"zone3\", \"zone4\", \"zone5\", \"zone6\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(zone1, index=zone1.index).rename(\n",
    "    columns={\"Number of airline passengers\": \"zone1\"}\n",
    ")\n",
    "\n",
    "df[\"zone2\"] = 10 + zone1 * 5\n",
    "df[\"zone3\"] = zone1 * 0.9 - 50\n",
    "df[\"zone4\"] = zone1 ** 1.5\n",
    "df[\"zone5\"] = zone1 * 10 - 500\n",
    "df[\"zone6\"] = 10 + (10 * zone1) + (0.05 * (zone1 ** 2))\n",
    "\n",
    "df = (\n",
    "    df.melt(ignore_index=False)\n",
    "    .set_index([\"variable\", df.melt(ignore_index=False).index])\n",
    "    .rename_axis([\"airport\", \"timepoints\"], axis=0)\n",
    "    .rename(columns={\"value\": \"passengers\"})\n",
    ")\n",
    "\n",
    "# df['country'] = \"USA\"\n",
    "df.loc[\n",
    "    df.index.get_level_values(level=\"airport\").isin([\"zone1\", \"zone2\", \"zone3\"]),\n",
    "    \"state\",\n",
    "] = \"CA\"\n",
    "df.loc[\n",
    "    df.index.get_level_values(level=\"airport\").isin([\"zone1\", \"zone2\"]), \"city\"\n",
    "] = \"LA\"\n",
    "df.loc[df.index.get_level_values(level=\"airport\").isin([\"zone3\"]), \"city\"] = \"SF\"\n",
    "\n",
    "\n",
    "df.loc[\n",
    "    df.index.get_level_values(level=\"airport\").isin([\"zone4\", \"zone5\", \"zone6\"]),\n",
    "    \"state\",\n",
    "] = \"NY\"\n",
    "df.loc[\n",
    "    df.index.get_level_values(level=\"airport\").isin([\"zone4\", \"zone5\"]), \"city\"\n",
    "] = \"NYC\"\n",
    "df.loc[df.index.get_level_values(level=\"airport\").isin([\"zone6\"]), \"city\"] = \"BF\"\n",
    "\n",
    "df = df.set_index([\"state\", \"city\", df.index])\n",
    "df\n",
    "\n",
    "\n",
    "# df.droplevel(level=-1).index.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate full hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fh = aggregate_hierarchy(df, flatten_single_levels=True)\n",
    "\n",
    "df_fh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecast each level\n",
    "\n",
    "here we will forecast each unique level outside `timepoints`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.exp_smoothing import ExponentialSmoothing\n",
    "from sktime.forecasting.model_selection import temporal_train_test_split\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids = df_fh.droplevel(level=\"timepoints\").index.unique()\n",
    "\n",
    "model_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set up loop for forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in model_ids:\n",
    "mods = {}\n",
    "prds = {}\n",
    "\n",
    "for i in model_ids:\n",
    "    # i = model_ids[0]\n",
    "    y_train, y_test = temporal_train_test_split(df_fh.loc[i], test_size=36)\n",
    "    fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
    "    forecaster = ExponentialSmoothing(trend=\"add\", seasonal=\"additive\", sp=12)\n",
    "    mods[i] = forecaster.fit(y_train)\n",
    "    prds[i] = forecaster.predict(fh)\n",
    "    # plot_series(y_train, y_test, y_pred, labels=[\"y_train\", \"y_test\", \"y_pred\"])\n",
    "    print(i)\n",
    "    print(mean_absolute_percentage_error(y_test, prds[i], symmetric=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prds = (\n",
    "    pd.concat(prds)\n",
    "    .rename_axis(df_fh.index.names, axis=0)\n",
    "    .rename(columns={\"passengers\": \"y_pred\"})\n",
    ")\n",
    "\n",
    "# join with meas\n",
    "prds = pd.concat([prds, df_fh], axis=1, join=\"inner\").rename(\n",
    "    columns={\"passengers\": \"y_true\"}\n",
    ")\n",
    "\n",
    "prds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconcile - Bottom Up\n",
    "\n",
    "Bottom up is easy we just sum the bottome levels much like aggregate function.\n",
    "\n",
    "But we want it to be compatible with other methods which go like\n",
    "    \n",
    "    - get y 'base' forecasts for all series (previous section)\n",
    "    - get S matrix from df index (defined by hierarchy structure)\n",
    "    - get G matrix for recon (defined by recon method)\n",
    "    - reconcile forecasts - SGy (all methods)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Here is the S matrix for our example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s_matrix(df):\n",
    "\n",
    "    # get bottom level indexes\n",
    "    bl_inds = (\n",
    "        df.loc[~(df.index.get_level_values(level=-2).isin([\"__total\"]))]\n",
    "        .index.droplevel(\"timepoints\")\n",
    "        .unique()\n",
    "    )\n",
    "\n",
    "    # get all level indexes\n",
    "    al_inds = df.droplevel(level=\"timepoints\").index.unique()\n",
    "\n",
    "    s_matrix = pd.DataFrame(\n",
    "        [[0.0 for i in range(len(bl_inds))] for i in range(len(al_inds))], index=al_inds\n",
    "    )\n",
    "\n",
    "    #\n",
    "    s_matrix.columns = list(bl_inds.get_level_values(level=-1))\n",
    "\n",
    "    # now insert indicator for bottom level\n",
    "    for i in s_matrix.columns:\n",
    "        s_matrix.loc[s_matrix.index.get_level_values(-1) == i, i] = 1.0\n",
    "\n",
    "    # now for each unique column\n",
    "    for j in s_matrix.columns:\n",
    "\n",
    "        # find bottom index id\n",
    "        inds = list(s_matrix.index[s_matrix.index.get_level_values(level=-1).isin([j])])\n",
    "\n",
    "        # generate new tuples for the aggregate levels\n",
    "        for i in range(len(inds[0])):\n",
    "            tmp = list(inds[i])\n",
    "            tmp[-(i + 1)] = \"__total\"\n",
    "            inds.append(tuple(tmp))\n",
    "\n",
    "        # insrt indicator for aggregates\n",
    "        for i in inds:\n",
    "            s_matrix.loc[i, j] = 1.0\n",
    "\n",
    "    # drop new levels not present in orginal matrix\n",
    "    s_matrix.dropna(inplace=True)\n",
    "\n",
    "    return s_matrix\n",
    "\n",
    "\n",
    "s_test = get_s_matrix(prds)\n",
    "\n",
    "s_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now the G matrix for the bottom-up method\n",
    "        \n",
    "        - note for some reconcilers this will have to access each models residuals\n",
    "        - the G matrix is used to transform the original forecasts at all levels to new bottom level forecasts\n",
    "        - it is then combined with the summation matrix S\n",
    "        - for bottom up the G matrix should be the transpose of the S matrix with `__total` level indicators set to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_g_matrix_bu(df):\n",
    "\n",
    "    # get bottom level indexes\n",
    "    bl_inds = (\n",
    "        df.loc[~(df.index.get_level_values(level=-2).isin([\"__total\"]))]\n",
    "        .index.droplevel(\"timepoints\")\n",
    "        .unique()\n",
    "    )\n",
    "\n",
    "    # get all level indexes\n",
    "    al_inds = df.droplevel(level=\"timepoints\").index.unique()\n",
    "\n",
    "    g_matrix = pd.DataFrame(\n",
    "        [[0.0 for i in range(len(bl_inds))] for i in range(len(al_inds))], index=al_inds\n",
    "    )\n",
    "\n",
    "    #\n",
    "    g_matrix.columns = list(bl_inds.get_level_values(level=-1))\n",
    "\n",
    "    # now insert indicator for bottom level\n",
    "    for i in g_matrix.columns:\n",
    "        g_matrix.loc[g_matrix.index.get_level_values(-1) == i, i] = 1.0\n",
    "\n",
    "    return g_matrix.transpose()\n",
    "\n",
    "\n",
    "g_test = get_g_matrix_bu(prds)\n",
    "\n",
    "g_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Now reconcile using SGy\n",
    "        - this is the same no matter the reconciliation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note these should all be pandas df with the correct indexing\n",
    "# using numpy for now..would be good to keep index matching...\n",
    "def reconcile(base_fc, s_matrix, g_matrix):\n",
    "    # return s_matrix.dot(g_matrix.dot(base_fc))\n",
    "    return np.dot(s_matrix, np.dot(g_matrix, base_fc))\n",
    "\n",
    "\n",
    "prds[\"y_reco_bu\"] = (\n",
    "    prds[[\"y_pred\"]]\n",
    "    .groupby(level=\"timepoints\")\n",
    "    .transform(lambda x: reconcile(x, s_test, g_test))\n",
    ")\n",
    "\n",
    "prds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prds.loc[prds.index.get_level_values(level=-1) == \"1958-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS reconciliation\n",
    "\n",
    "    - Now all we need is the new g_matrix method\n",
    "    - now all this method needs is the summation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_g_matrix_ols(df):\n",
    "\n",
    "    smat = get_s_matrix(df)\n",
    "\n",
    "    g_ols = pd.DataFrame(\n",
    "        np.dot(inv(np.dot(np.transpose(smat), smat)), np.transpose(smat))\n",
    "    )\n",
    "\n",
    "    g_ols = g_ols.transpose()\n",
    "    g_ols = g_ols.set_index(smat.index)\n",
    "    g_ols.columns = smat.columns\n",
    "    g_ols = g_ols.transpose()\n",
    "\n",
    "    return g_ols\n",
    "\n",
    "\n",
    "g_test_ols = get_g_matrix_ols(prds)\n",
    "\n",
    "g_test_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prds[\"y_reco_ols\"] = (\n",
    "    prds[[\"y_pred\"]]\n",
    "    .groupby(level=\"timepoints\")\n",
    "    .transform(lambda x: reconcile(x, s_test, g_test_ols))\n",
    ")\n",
    "\n",
    "prds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This seems to work fine as well\n",
    "\n",
    "    - note the bottom level forecasts have now changed as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prds.loc[prds.index.get_level_values(level=-1) == \"1958-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe need some significance testing here :p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in model_ids:\n",
    "#     # print(i)\n",
    "#     # print(\n",
    "#     #     mean_absolute_percentage_error(\n",
    "#     #         prds.loc[i, \"y_true\"], prds.loc[i, \"y_pred\"], symmetric=True\n",
    "#     #     )\n",
    "#     # )\n",
    "#     # print(\n",
    "#     #     mean_absolute_percentage_error(\n",
    "#     #         prds.loc[i, \"y_true\"], prds.loc[i, \"y_reco_bu\"], symmetric=True\n",
    "#     #     )\n",
    "#     # )\n",
    "#     # print(\n",
    "#     #     mean_absolute_percentage_error(\n",
    "#     #         prds.loc[i, \"y_true\"], prds.loc[i, \"y_reco_ols\"], symmetric=True\n",
    "#     #     )\n",
    "#     # )\n",
    "#     plot_series(\n",
    "#         prds.loc[i, 'y_true'],\n",
    "#         prds.loc[i, 'y_pred'],\n",
    "#         prds.loc[i, 'y_reco_bu'],\n",
    "#         prds.loc[i, 'y_reco_ols'],\n",
    "#         labels=[\"y_test\", \"y_pred\", \"y_pred_bu\", \"y_pred_ols\"],\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we could maybe work it like this\n",
    "\n",
    "\n",
    "class (panel_forecaster)\n",
    "    \n",
    "    - fit\n",
    "    - predict\n",
    "    - train_test_temporal split?\n",
    "    - list of model specs\n",
    "\n",
    "class hierarchical_forecaster(panel_forecaster)\n",
    "    \n",
    "    Includes the aggregated levels for the panel.\n",
    "    \n",
    "    Inherits methods from above and adds g matrix methods that need information from model fits/original data\n",
    "\n",
    "    - get_g_matrix_wlsvar\n",
    "    - get_g_matrix_mint\n",
    "    - get_g_matrix_mint_shrink\n",
    "    - get_g_matrix_topdown\n",
    "    - predict generates multiindex\n",
    "\n",
    "class reconcile(Transfromer, predictions: multi-index with '__total' present, method = \"bu\"):\n",
    "\n",
    "    Inherets transfromer methods? and includes reconciliation methods that don't depend on historic/residual data.\n",
    "\n",
    "    Checks we have predicttions from hierarchical forecaster then\n",
    "\n",
    "    - fit\n",
    "    - predict, i.e. reconcile from this notebook\n",
    "    - get_s_matrix\n",
    "    - get_g_matrix_bu\n",
    "    - get_g_matrix_ols\n",
    "    - get_g_matrix_wlsstr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- generate full hierarchy\n",
    "- individual forecasts\n",
    "- Get S (summation) matrix (all recon methods)\n",
    "- Get G (recon) matrix (method dependent)\n",
    "- reconcile (all methods)\n",
    "\n",
    "\n",
    "inheret from base classes (base estimator/forecaster) \n",
    "    - inhereting will be easier\n",
    "\n",
    "- initialisation of class\n",
    "    - recon method (method = \"bu\", \"ols\")\n",
    "    - work for every dataframe\n",
    "\n",
    "- call that class on a frame\n",
    "    - list of forecasters (flexible, to do)\n",
    "\n",
    "- forecaster method call returns recon predicts\n",
    "    - data in it\n",
    "    - list of forecasters (simple for now)\n",
    "\n",
    "- hidden methods \n",
    "    - checks for data \n",
    "    - check for final predictions\n",
    "\n",
    "\n",
    "\n",
    "- split it up into two methods in the same class?\n",
    "- store predictions in methods of class self."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c1eb1c2818a749c31c67be5c4cb66d4609f775387358a3054790d55ee191d060"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('sktime-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
